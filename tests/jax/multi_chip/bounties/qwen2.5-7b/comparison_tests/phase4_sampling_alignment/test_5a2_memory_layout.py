#!/usr/bin/env python3
"""
Phase 5A.2: Memory Layout Optimization
Applying Phase 3 transpose expertise to cache storage formats
Target: Optimal cache performance with perfect correctness
"""

import os
import sys
import time
import numpy as np
import torch
import jax
import jax.numpy as jnp
import logging
from typing import List, Tuple, Dict, Optional

# Add parent directory to path to import model components
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

# Setup logging with Phase 3 standards
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("phase5a2_memory")

class Phase5A2MemoryLayoutValidator:
    """Phase 5A.2: Memory layout optimization with Phase 3 transpose expertise"""
    
    def __init__(self):
        self.precision_threshold = 1e-9  # Very strict for memory layout operations
        self.performance_threshold = 2.0  # Max acceptable performance ratio
        self.validation_passed = True
        
        # Test configurations for memory optimization
        self.test_configs = [
            {"batch_size": 1, "seq_len": 1, "num_kv_heads": 32, "head_dim": 128},
            {"batch_size": 1, "seq_len": 10, "num_kv_heads": 32, "head_dim": 128},
            {"batch_size": 1, "seq_len": 50, "num_kv_heads": 32, "head_dim": 128},
            {"batch_size": 1, "seq_len": 1, "num_kv_heads": 8, "head_dim": 128},  # GQA
        ]
        
    def log_validation_result(self, test_name: str, passed: bool, details: str = ""):
        """Phase 3 style validation logging"""
        status = "‚úÖ" if passed else "‚ùå"
        logger.info(f"{status} {test_name}: {details}")
        if not passed:
            self.validation_passed = False
    
    def create_test_cache_data(self, config: Dict, seq_len: int) -> Tuple[np.ndarray, np.ndarray]:
        """Create test cache data with proper format"""
        batch_size = config["batch_size"]
        num_kv_heads = config["num_kv_heads"]
        head_dim = config["head_dim"]
        
        np.random.seed(42)
        k_data = np.random.randn(batch_size, seq_len, num_kv_heads, head_dim).astype(np.float32)
        v_data = np.random.randn(batch_size, seq_len, num_kv_heads, head_dim).astype(np.float32)
        
        return k_data, v_data
    
    def test_cache_storage_formats(self, config: Dict, seq_len: int) -> bool:
        """Test different cache storage formats for efficiency"""
        
        # Handle empty cache case
        if seq_len == 0:
            return True, f"Empty cache: batch={config['batch_size']}, seq={seq_len}, heads={config['num_kv_heads']}"
        
        k_data, v_data = self.create_test_cache_data(config, seq_len)
        
        # Format 1: [batch, seq, num_kv_heads, head_dim] (our current format)
        format1_k = jnp.array(k_data)
        format1_v = jnp.array(v_data)
        
        # Format 2: [batch, num_kv_heads, seq, head_dim] (PyTorch typical)
        format2_k = jnp.transpose(format1_k, (0, 2, 1, 3))
        format2_v = jnp.transpose(format1_v, (0, 2, 1, 3))
        
        # Format 3: [batch, seq, num_kv_heads * head_dim] (flattened)
        format3_k = format1_k.reshape(config["batch_size"], seq_len, -1)
        format3_v = format1_v.reshape(config["batch_size"], seq_len, -1)
        
        # Test retrieval from each format
        retrieval_tests = []
        
        # Test 1: Retrieve last token from each format
        last_token_idx = seq_len - 1 if seq_len > 0 else 0
        
        if seq_len > 0:
            # Format 1 retrieval
            last_k_f1 = format1_k[:, last_token_idx, :, :]
            last_v_f1 = format1_v[:, last_token_idx, :, :]
            
            # Format 2 retrieval (transpose back)
            last_k_f2 = format2_k[:, :, last_token_idx, :]
            last_v_f2 = format2_v[:, :, last_token_idx, :]
            
            # Format 3 retrieval (reshape back)
            last_k_f3 = format3_k[:, last_token_idx, :].reshape(config["batch_size"], config["num_kv_heads"], config["head_dim"])
            last_v_f3 = format3_v[:, last_token_idx, :].reshape(config["batch_size"], config["num_kv_heads"], config["head_dim"])
            
            # Compare retrievals (format 2 needs transpose to match format 1)
            last_k_f2_matched = jnp.transpose(last_k_f2, (0, 1, 2))  # Already correct
            last_v_f2_matched = jnp.transpose(last_v_f2, (0, 1, 2))
            
            # Compare format 1 vs format 2
            k_diff_f1_f2 = jnp.max(jnp.abs(last_k_f1 - last_k_f2_matched))
            v_diff_f1_f2 = jnp.max(jnp.abs(last_v_f1 - last_v_f2_matched))
            
            # Compare format 1 vs format 3
            k_diff_f1_f3 = jnp.max(jnp.abs(last_k_f1 - last_k_f3))
            v_diff_f1_f3 = jnp.max(jnp.abs(last_v_f1 - last_v_f3))
            
            format_consistency = (k_diff_f1_f2 < self.precision_threshold and 
                                v_diff_f1_f2 < self.precision_threshold and
                                k_diff_f1_f3 < self.precision_threshold and
                                v_diff_f1_f3 < self.precision_threshold)
        else:
            format_consistency = True  # Empty cache case
            k_diff_f1_f2 = v_diff_f1_f2 = k_diff_f1_f3 = v_diff_f1_f3 = 0.0
        
        details = (f"batch={config['batch_size']}, seq={seq_len}, heads={config['num_kv_heads']}: "
                  f"f1_vs_f2(k={k_diff_f1_f2:.2e},v={v_diff_f1_f2:.2e}), "
                  f"f1_vs_f3(k={k_diff_f1_f3:.2e},v={v_diff_f1_f3:.2e})")
        
        return format_consistency, details
    
    def test_cache_access_patterns(self, config: Dict, seq_len: int) -> bool:
        """Test different cache access patterns for efficiency"""
        
        if seq_len == 0:
            return True, "Empty cache - no access patterns to test"
        
        k_data, v_data = self.create_test_cache_data(config, seq_len)
        
        # Create cache in our standard format
        cache_k = jnp.array(k_data)
        cache_v = jnp.array(v_data)
        
        access_patterns = []
        
        # Pattern 1: Sequential access (typical for generation)
        sequential_k = []
        sequential_v = []
        for i in range(min(seq_len, 3)):  # Test first 3 tokens
            token_k = cache_k[:, i, :, :]
            token_v = cache_v[:, i, :, :]
            sequential_k.append(token_k)
            sequential_v.append(token_v)
        
        # Pattern 2: Batch access (all tokens at once)
        batch_k = cache_k  # Entire cache
        batch_v = cache_v
        
        # Pattern 3: Head-wise access
        head_wise_k = []
        head_wise_v = []
        for head in range(min(config["num_kv_heads"], 4)):  # Test first 4 heads
            head_k = cache_k[:, :, head, :]
            head_v = cache_v[:, :, head, :]
            head_wise_k.append(head_k)
            head_wise_v.append(head_v)
        
        # All access patterns should preserve data integrity
        access_consistent = True
        
        # Verify sequential access preserves original data
        if sequential_k:
            reconstructed_k = jnp.stack(sequential_k, axis=1)
            reconstructed_v = jnp.stack(sequential_v, axis=1)
            
            original_subset_k = cache_k[:, :len(sequential_k), :, :]
            original_subset_v = cache_v[:, :len(sequential_v), :, :]
            
            k_sequential_diff = jnp.max(jnp.abs(reconstructed_k - original_subset_k))
            v_sequential_diff = jnp.max(jnp.abs(reconstructed_v - original_subset_v))
            
            access_consistent = (k_sequential_diff < self.precision_threshold and 
                               v_sequential_diff < self.precision_threshold)
        else:
            k_sequential_diff = v_sequential_diff = 0.0
        
        details = (f"batch={config['batch_size']}, seq={seq_len}, heads={config['num_kv_heads']}: "
                  f"sequential_diff(k={k_sequential_diff:.2e},v={v_sequential_diff:.2e})")
        
        return access_consistent, details
    
    def test_cache_concatenation_efficiency(self, config: Dict) -> bool:
        """Test efficiency of cache concatenation operations"""
        
        # Create past cache (simulate growing cache)
        past_lengths = [0, 1, 5, 10]
        concat_times = []
        
        for past_len in past_lengths:
            past_k_data, past_v_data = self.create_test_cache_data(config, past_len)
            current_k_data, current_v_data = self.create_test_cache_data(config, 1)  # Single new token
            
            past_k = jnp.array(past_k_data)
            past_v = jnp.array(past_v_data)
            current_k = jnp.array(current_k_data)
            current_v = jnp.array(current_v_data)
            
            # Time concatenation operation
            start_time = time.time()
            
            # Multiple concatenations to get meaningful timing
            for _ in range(100):
                new_k = jnp.concatenate([past_k, current_k], axis=1)
                new_v = jnp.concatenate([past_v, current_v], axis=1)
            
            end_time = time.time()
            concat_time = (end_time - start_time) / 100  # Average per operation
            concat_times.append(concat_time)
            
            # Verify correctness
            expected_len = past_len + 1
            len_correct = (new_k.shape[1] == expected_len and new_v.shape[1] == expected_len)
            
            if not len_correct:
                return False, f"Concatenation length incorrect: expected {expected_len}, got k={new_k.shape[1]}, v={new_v.shape[1]}"
        
        # Check that concatenation time scales reasonably
        if len(concat_times) > 1:
            time_ratio = max(concat_times) / min(concat_times) if min(concat_times) > 0 else 1.0
            performance_acceptable = time_ratio < self.performance_threshold
        else:
            performance_acceptable = True
            time_ratio = 1.0
        
        details = (f"batch={config['batch_size']}, heads={config['num_kv_heads']}: "
                  f"concat_times={[f'{t:.2e}' for t in concat_times]}, "
                  f"time_ratio={time_ratio:.2f}")
        
        return performance_acceptable, details
    
    def test_memory_efficiency_comparison(self, config: Dict, seq_len: int) -> bool:
        """Compare memory efficiency between different storage approaches"""
        
        # Handle empty cache case
        if seq_len == 0:
            return True, f"Empty cache: batch={config['batch_size']}, seq={seq_len}, heads={config['num_kv_heads']}"
        
        k_data, v_data = self.create_test_cache_data(config, seq_len)
        
        # Approach 1: Separate K,V tensors (our current approach)
        separate_k = jnp.array(k_data)
        separate_v = jnp.array(v_data)
        
        # Approach 2: Interleaved K,V
        interleaved_kv = jnp.stack([separate_k, separate_v], axis=-1)  # [..., 2] for K,V
        
        # Approach 3: Concatenated K,V along head dimension
        concat_kv = jnp.concatenate([separate_k, separate_v], axis=2)  # Double the heads
        
        # Test data integrity for each approach
        approaches_valid = []
        
        # Validate separate approach (baseline)
        separate_valid = True  # By definition
        approaches_valid.append(("separate", separate_valid))
        
        # Validate interleaved approach
        recovered_k_interleaved = interleaved_kv[..., 0]
        recovered_v_interleaved = interleaved_kv[..., 1]
        
        k_interleaved_diff = jnp.max(jnp.abs(recovered_k_interleaved - separate_k))
        v_interleaved_diff = jnp.max(jnp.abs(recovered_v_interleaved - separate_v))
        
        interleaved_valid = (k_interleaved_diff < self.precision_threshold and 
                           v_interleaved_diff < self.precision_threshold)
        approaches_valid.append(("interleaved", interleaved_valid))
        
        # Validate concatenated approach
        mid_head = config["num_kv_heads"]
        recovered_k_concat = concat_kv[:, :, :mid_head, :]
        recovered_v_concat = concat_kv[:, :, mid_head:, :]
        
        k_concat_diff = jnp.max(jnp.abs(recovered_k_concat - separate_k))
        v_concat_diff = jnp.max(jnp.abs(recovered_v_concat - separate_v))
        
        concat_valid = (k_concat_diff < self.precision_threshold and 
                       v_concat_diff < self.precision_threshold)
        approaches_valid.append(("concat", concat_valid))
        
        all_approaches_valid = all(valid for _, valid in approaches_valid)
        
        details = (f"batch={config['batch_size']}, seq={seq_len}, heads={config['num_kv_heads']}: "
                  f"separate=‚úì, interleaved={'‚úì' if interleaved_valid else '‚úó'}, "
                  f"concat={'‚úì' if concat_valid else '‚úó'}")
        
        return all_approaches_valid, details
    
    def run_memory_layout_validation(self) -> bool:
        """Run comprehensive memory layout optimization tests"""
        
        logger.info("üöÄ Starting Phase 5A.2: Memory Layout Optimization")
        logger.info("Target: Optimal cache performance with perfect correctness")
        
        # Test 1: Cache storage formats
        logger.info("üìä Testing cache storage formats...")
        for config in self.test_configs:
            for seq_len in [0, 1, 10]:
                passed, details = self.test_cache_storage_formats(config, seq_len)
                self.log_validation_result(f"Storage formats", passed, details)
        
        # Test 2: Cache access patterns
        logger.info("üìä Testing cache access patterns...")
        for config in self.test_configs:
            for seq_len in [1, 10]:  # Skip empty cache for access patterns
                passed, details = self.test_cache_access_patterns(config, seq_len)
                self.log_validation_result(f"Access patterns", passed, details)
        
        # Test 3: Cache concatenation efficiency
        logger.info("üìä Testing cache concatenation efficiency...")
        for config in self.test_configs[:2]:  # Use first 2 configs for efficiency tests
            passed, details = self.test_cache_concatenation_efficiency(config)
            self.log_validation_result(f"Concatenation efficiency", passed, details)
        
        # Test 4: Memory efficiency comparison
        logger.info("üìä Testing memory efficiency approaches...")
        for config in self.test_configs:
            for seq_len in [1, 10]:
                passed, details = self.test_memory_efficiency_comparison(config, seq_len)
                self.log_validation_result(f"Memory efficiency", passed, details)
        
        # Final validation summary
        if self.validation_passed:
            logger.info("üéâ Phase 5A.2 PASSED: Optimal cache performance with perfect correctness!")
            logger.info("‚úÖ Storage format consistency validated")
            logger.info("‚úÖ Access pattern efficiency verified")
            logger.info("‚úÖ Concatenation performance acceptable")
            logger.info("‚úÖ Memory layout options validated")
        else:
            logger.error("‚ùå Phase 5A.2 FAILED: Memory layout optimization issues detected")
            logger.error("üîß Review cache storage and access patterns")
        
        return self.validation_passed

def main():
    """Main Phase 5A.2 validation entry point"""
    
    print("="*80)
    print("PHASE 5A.2: MEMORY LAYOUT OPTIMIZATION")
    print("Applying Phase 3 transpose expertise to cache storage formats")
    print("="*80)
    
    validator = Phase5A2MemoryLayoutValidator()
    success = validator.run_memory_layout_validation()
    
    print("\n" + "="*80)
    if success:
        print("üéâ PHASE 5A.2 VALIDATION COMPLETE - ALL TESTS PASSED")
        print("‚úÖ Optimal cache performance with perfect correctness")
    else:
        print("‚ùå PHASE 5A.2 VALIDATION FAILED")
        print("üîß Memory layout optimization requires improvements")
    print("="*80)
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 